{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 超参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = datasets.load_digits()\n",
    "X = digits.data\n",
    "y = digits.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9888888888888889"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    " \n",
    "knn_clf = KNeighborsClassifier(n_neighbors=3)\n",
    "knn_clf.fit(X_train, y_train)\n",
    "# knn_clf.predict(X_test)\n",
    "knn_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nn_neighbors 之前我们都是随意传 3, 5, 6\\n\\n但是究竟传什么才是最好的呢?(后面会用 超参数GridSearchCV网格搜索)\\n\\n 超参数 就是运行机器学习算法之前需要指定的参数\\n\\n\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "n_neighbors 之前我们都是随意传 3, 5, 6\n",
    "\n",
    "但是究竟传什么才是最好的呢?(后面会用 超参数GridSearchCV网格搜索)\n",
    "\n",
    " 超参数 就是运行机器学习算法之前需要指定的参数\n",
    " \n",
    " 注意这门课不是为了从底层设计机器学习算法库, 而是为了更好地使用官方的机器学习算法库\n",
    "\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 寻找最好的k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_k =  4\n",
      "best_score =  0.9916666666666667\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "best_score: 最好准确率的值初始化为0\n",
    "best_k = -1\n",
    "\n",
    "通过循环的形式来寻找最好的k\n",
    "\n",
    "调参过程\n",
    "'''\n",
    "best_score = 0.0\n",
    "best_k = -1\n",
    "\n",
    "for k in range(1, 11):\n",
    "    knn_clf = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn_clf.fit(X_train, y_train)\n",
    "    score = knn_clf.score(X_test, y_test)\n",
    "    if score > best_score:\n",
    "        best_k = k\n",
    "        best_score = score\n",
    "\n",
    "print(\"best_k = \", best_k)\n",
    "print(\"best_score = \", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_k =  8\n",
      "best_score =  0.9861111111111112\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "上面我们循环只进行到了10\n",
    "\n",
    "我们可以试试 8~20 的范围有没有可能得到更好的结果\n",
    "'''\n",
    "# best_score = 0.0\n",
    "# best_k = -1\n",
    "\n",
    "# for k in range(8, 21):\n",
    "#     knn_clf = KNeighborsClassifier(n_neighbors=k)\n",
    "#     knn_clf.fit(X_train, y_train)\n",
    "#     score = knn_clf.score(X_test, y_test)\n",
    "#     if score > best_score:\n",
    "#         best_k = k\n",
    "#         best_score = score\n",
    "\n",
    "# print(\"best_k = \", best_k)\n",
    "# print(\"best_score = \", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n注意: 不要以为 kNN 中只有 k 一个超参数\\n\\n还有 权值!\\n\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "注意: 不要以为 kNN 中只有 k 一个超参数\n",
    "\n",
    "还有 权值!\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 考虑距离? 不考虑距离?\n",
    "\n",
    "使用uniform好呢, 还是distance好呢?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_method =  uniform\n",
      "best_k =  4\n",
      "best_score =  0.9916666666666667\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "我们这里设置一个新的参数 best_method, 表示我们到底要不要考虑距离的权重, 初始化为空\n",
    "\n",
    "初始化 method 循环, 再每一种method情况下再来看去不同的值结果怎么样\n",
    "(在KNeighborsClassifier中传入参数weighs=method)\n",
    "\n",
    "如果score > best_score, 除了记录之前的best_k, best_score,\n",
    "还要记录 best_method\n",
    "'''\n",
    "\n",
    "best_method = \"\"\n",
    "best_score = 0.0\n",
    "best_k = -1\n",
    "\n",
    "for method in ['uniform', 'distance']:\n",
    "    for k in range(1, 11):\n",
    "        knn_clf = KNeighborsClassifier(n_neighbors=k, weights=method)\n",
    "        knn_clf.fit(X_train, y_train)\n",
    "        score = knn_clf.score(X_test, y_test)\n",
    "        if score > best_score:\n",
    "            best_k = k\n",
    "            best_score = score\n",
    "            best_method = method\n",
    "\n",
    "print(\"best_method = \", best_method)            \n",
    "print(\"best_k = \", best_k)\n",
    "print(\"best_score = \", best_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>我们可以发现, 对于手写数字识别这个例子来说, 我们找到了最佳调用kNN的方法依然是使用我们的uniform方法, 相应的k值取4, 预测分数是0.9916...</font>\n",
    "\n",
    "<br/>\n",
    "\n",
    "<font size=3>距离, 什么是距离呢?</font>\n",
    "\n",
    "to .md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font size=3>搜索明可夫斯基距离相应的p</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'''\n",
    "现在我们是对 best_p 进行搜索\n",
    "\n",
    "外层 k 循环不变, \n",
    "里面嵌套一层 p 循环 从 1~5\n",
    "\n",
    "那么我们 knn_clf 的 weighs='distance', p=p\n",
    "\n",
    "那么现在我们就是对 k 和 p 这两个超参数进行搜索\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_p =  2\n",
      "best_k =  3\n",
      "best_score =  0.9888888888888889\n",
      "Wall time: 36.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "best_p = \"\"\n",
    "best_score = 0.0\n",
    "best_k = -1\n",
    "\n",
    "for k in range(1, 11):\n",
    "    for p in range(1, 6):\n",
    "        knn_clf = KNeighborsClassifier(n_neighbors=k, weights='distance', p=p)\n",
    "        knn_clf.fit(X_train, y_train)\n",
    "        score = knn_clf.score(X_test, y_test)\n",
    "        if score > best_score:\n",
    "            best_k = k\n",
    "            best_score = score\n",
    "            best_p = p\n",
    "\n",
    "print(\"best_p = \", best_p)            \n",
    "print(\"best_k = \", best_k)\n",
    "print(\"best_score = \", best_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面我们求出来了对于识别手写输入文字例子来说, 最好的 p 和 k 是 2 和 3\n",
    "\n",
    "这一节我们学习了什么是超参数, 即使对于 kNN 这样的算法, 还是具有很多的超参数, 不仅有 k, weighs, p 这3个\n",
    "\n",
    "那么对于超参数的选择, 我们就可以选择 这种搜索的策略, 来找到适合我们的超参数\n",
    "\n",
    "事实上, 这种搜索策略有一种专业的名字, 就叫做 网格搜索 GridSearchCV\n",
    "\n",
    "在上面就是 对 k * p 的网格中的每一个点所代表的数据进行搜索, 来找其中的最好值\n",
    "\n",
    "上面超参数 weighs 对 p 是有影响的, weighs='distance' 的时候才会有p\n",
    "\n",
    "也就是超参数之间还会存在 依赖 的关系, 那么我们怎么才能更好的将超参数全部列出来, 运行一遍程序就能找到最好的超参数组合呢?\n",
    "\n",
    "事实上, scikit-learn 中, 网格搜索封装了一个专门的函数, 我们调用这个网格搜索方法就能更好地实现超参数寻找的过程\n",
    "\n",
    "关于这个问题, 将在4.6节介绍"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
