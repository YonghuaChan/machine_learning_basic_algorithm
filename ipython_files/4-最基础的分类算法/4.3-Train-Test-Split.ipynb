{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 测试我们的算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font size=3>train test split</font>\n",
    "\n",
    "<br/>\n",
    "\n",
    "<font size=3>我们应该对原始数据集按照大概8:2的概率分成训练数据集和测试数据集, 测试数据集是用来测试我们通过训练数据集训练出来的模型的效果的</font>\n",
    "<br/>\n",
    "<font size=3>但是我们不能单纯直接取原始数据集的前80%, 因为数据集一开始里面的数据并不是均匀分布的</font>\n",
    "<br/>\n",
    "\n",
    "\n",
    "* 所以我们要对原始数据集进行suffle乱序处理\n",
    "* 之后再取80%当做训练数据集\n",
    "\n",
    "我们看上面iris里面的X和y是分离的, 同时也是一一对应的, 我们不能将X进行随机化, 然后再对y进行随机化\n",
    "\n",
    "只有一起随机化, 才能保持一一对应\n",
    "\n",
    "用numpy将X和y合并一起, 随机化之后, 再拆分成特征矩阵和标签矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "标签分布不均\n",
    "'''\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "我们只对这 0~149 的索引进行乱序\n",
    "\n",
    "permutation: 返回随机排列一个序列，或返回一个置换范围。\n",
    "\n",
    "len(X): X的行数, 也就是样本的个数\n",
    "'''\n",
    "\n",
    "shuffle_indexes = np.random.permutation(len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([116, 136,  15,  34,  18,  47, 122,  39,  25,  29,  69,  91, 142,\n",
       "       149, 139, 141,  31,  62,  57, 115,  76,  51,  61,  24,  14, 121,\n",
       "        95,  37,  54, 106,  66,  20,  86,  75, 125,  46,  70,   5,   3,\n",
       "       134,  50, 146,  55, 133, 118,   4,  26,  38, 119, 148, 127,  68,\n",
       "        22, 147, 129,  81,  79, 114,  36, 111,  49,  63,  89, 132,  80,\n",
       "        87,  40,  23, 110,  43,  21, 120,  53, 103,   0,  97,  71,  73,\n",
       "       138,  92,  44, 100, 131,  60, 113, 108, 143,  48,   8, 135,  99,\n",
       "       128,   1, 101, 126,  42, 145,  59,  84,  32,  52,   7,  82,  33,\n",
       "        90,  35, 144, 107,  13,  16, 109,  19,  45,  78,  94, 124, 130,\n",
       "        17, 105,  30,  41,  28, 104,  88,  10,  93,  58,  65, 102,   2,\n",
       "        56,  12,  67,  83, 140,  11,   9, 112,  64,  98, 117,  27,   6,\n",
       "        77,  72,  96, 123,  74,  85, 137])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "长度和X相等 的 随机的索引序列\n",
    "'''\n",
    "shuffle_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "测试比例: \n",
    "\n",
    "因为有可能是浮点数, 所以取整\n",
    "'''\n",
    "test_ratio = 0.8\n",
    "test_size = int(len(X) * test_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "这样我们就获得了测试比例的大小\n",
    "\n",
    "'''\n",
    "test_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "我们取 0 ->test_size 长度的随机索引序列左右训练数据集的索引\n",
    "\n",
    "    取 test_size -> 最后 长度的随机索引序列左右测试数据集的索引\n",
    "'''\n",
    "train_indexes = shuffle_indexes[:test_size]\n",
    "test_indexes = shuffle_indexes[test_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "只要我们获得了训练数据集的索引还有测试数据集的索引\n",
    "\n",
    "我们就能使用 fancy indexing 来得出训练数据集和测试数据集\n",
    "'''\n",
    "X_train = X[train_indexes]\n",
    "y_train = y[train_indexes]\n",
    "\n",
    "X_test = X[test_indexes]\n",
    "y_test = y[test_indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120, 4)\n",
      "(120,)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "得出训练数据集 X_train - 矩阵\n",
    "\n",
    "训练数据集对应的标签 y_train - 向量\n",
    "\n",
    "'''\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 4)\n",
      "(30,)\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font size=3>使用我们的算法</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', 'D:\\\\Python\\\\Anaconda3\\\\python36.zip', 'D:\\\\Python\\\\Anaconda3\\\\DLLs', 'D:\\\\Python\\\\Anaconda3\\\\lib', 'D:\\\\Python\\\\Anaconda3', 'C:\\\\Users\\\\Yukirito\\\\AppData\\\\Roaming\\\\Python\\\\Python36\\\\site-packages', 'D:\\\\Python\\\\Anaconda3\\\\lib\\\\site-packages', 'D:\\\\Python\\\\Anaconda3\\\\lib\\\\site-packages\\\\win32', 'D:\\\\Python\\\\Anaconda3\\\\lib\\\\site-packages\\\\win32\\\\lib', 'D:\\\\Python\\\\Anaconda3\\\\lib\\\\site-packages\\\\Pythonwin', 'D:\\\\Python\\\\Anaconda3\\\\lib\\\\site-packages\\\\IPython\\\\extensions', 'C:\\\\Users\\\\Yukirito\\\\.ipython', '../', '../../', '../../../']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "# 动态添加test_package文件夹的路径，为了能让此文件夹下的\n",
    "# 自定义包成功的导入\n",
    "# 要根据你自己的实际包的模块来决定路径。\n",
    "\n",
    "# sys.path.append('../')\n",
    "# sys.path.append('../../')\n",
    "# sys.path.append('../../../')\n",
    "\n",
    "# 打印所有python解释器可以搜索到的所有路径\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from playML.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "我们将原始的X和y传入train_test_split函数, 我们就可以直接得到X_train, X_test, y_train, y_test\n",
    "'''\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120, 4)\n",
      "(120,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 4)\n",
      "(30,)\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from playML.kNN import KNNClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "定义一个自己的KNN分类器\n",
    "'''\n",
    "\n",
    "my_knn_clf = KNNClassifier(k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNN(k=3)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "my_knn_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "将用训练数据集训练出来的KNN算法模型, 传入 测试数据集X_test, 得到结果 y_predict\n",
    "\n",
    "'''\n",
    "y_predict = my_knn_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 1, 1, 0, 2, 2, 1, 0, 1, 1, 2, 0, 1, 0, 1, 0, 0, 2, 2, 0, 1,\n",
       "       2, 1, 2, 0, 1, 1, 1, 0])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "得到30个预测的对应结果\n",
    "'''\n",
    "y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 1, 1, 0, 2, 2, 1, 0, 1, 2, 2, 0, 1, 0, 1, 0, 0, 2, 2, 0, 2,\n",
       "       1, 1, 2, 0, 1, 1, 1, 0])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "将测试数据集x_test的出来的预测结果y_predict和原本的标签对应的y_test进行比对\n",
    "'''\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "准确率我们只要看两个中有多少元素一样就行\n",
    "\n",
    "sum中 两个向量的比较返回的布尔值作为索引, 1表示相同, 用sum即可累加\n",
    "'''\n",
    "sum(y_predict == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "那么准确率 = 预测正确数 / 测试数据集数\n",
    "\n",
    "我们也可以发现KNN简单的思想下, 算法非常强大 \n",
    "\n",
    "'''\n",
    "sum(y_predict == y_test)/len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font size=3>scikit-learn中的train_test_split</font>\n",
    "\n",
    "我们来看看官方库中是如何的?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "实际上和我们实现的是一样的\n",
    "'''\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "我们可以发现 整个函数的设计接口是一样的\n",
    "\n",
    "test_size=0.2 : 测试数据集所占的百分比是20%, 不写的话默认的值也是0.2\n",
    "\n",
    "random_state=666: 随机种子\n",
    "'''\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120, 4)\n",
      "(120,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 4)\n",
      "(30,)\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n总结: \\n    在机器学习中非常重要和简单的测试机器学习算法性能的方法, \\n    就是将原始数据集进行train_test_split方法, \\n    用train的数据集进行训练, 用test的测试集进行测试\\n    \\n    下面将用train_test_split方法来具体进行模型的选择\\n\\n'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "总结: \n",
    "    在机器学习中非常重要和简单的测试机器学习算法性能的方法, \n",
    "    就是将原始数据集进行train_test_split方法, \n",
    "    用train的数据集进行训练, 用test的测试集进行测试\n",
    "    \n",
    "    下面将用train_test_split方法来具体进行模型的选择\n",
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
